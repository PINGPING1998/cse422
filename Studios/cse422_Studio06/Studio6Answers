1} Tara Renduchintala

2}
sing: sings the song Bilbo sings when setting off on his adventure
    in The Fellowship of the Ring for the inputted number of verses
dense_mm: creates and multiplies 2 NxN matrices where N is the inputted
    number      
parallel_dense_mm: creates and multiplies 2 NxN matrices where N is the inputted
    number   
sort: generates an array and sorts it

3}
time ./sing 1:
real 0m0.008s
user 0m0.000s
sys  0m0.002s

time ./sing 4:
real 0m0.049s
user 0m0.000s
sys  0m0.003s

time ./sort 4:
real 0m0.005s
user 0m0.001s
sys  0m0.000s

time ./sort 8:
real 0m0.010s
user 0m0.001s
sys  0m0.001s

time ./dense_mm 1:
real 0m0.005s
user 0m0.001s
sys  0m0.001s

time ./dense_mm 4:
real 0m0.006s
user 0m0.000s
sys  0m0.002s

time ./parallel_dense_mm 1:
real 0m0.024s
user 0m0.194s
sys  0m0.002s

time ./parallel_dense_mm 4:
real 0m0.032s
user 0m0.205s
sys  0m0.001s

4} 
Real: the amount of actual time (according to the wall clock) 
    spent on the process
User: the amount of time the process spent in User space
Sys: the amount of time the process spend in Kernel space

5}
time ./dense_mm 1000:
real 0m4.970s
user 0m4.954s
sys  0m0.014s

time ./parallel_dense_mm 1000:
real 0m0.447s
user 0m12.052s
sys  0m0.016s

From using the time command, it is evident that the real time
spent doing the non-parallel computaion is greater than when
parallel computation is being used. However, the time in userspace
is greater for parallel computing than it is for non-parallel computation.
The reason that the user time is greater is because the parallel program
is running mulitple threads at the same time and the user time
is the addition of all of the time spent in User space by those 
multiple threads.

6}
./sing 1000:
real 0m0.144s
user 0m0.005s
sys  0m0.031s

The user timing was significantly smaller than the sys timing.
This means that the process spent a lot more time in the kernel 
space than in user space. However, real time was a lot larger than
both user and sys time. 

In ./dense_mm the sys time was significantly lower than the user space
and that is most likely because there is no real computation 
done in user space in ./sing while there is a significant amount
done in ./dense_mm.

7}
Not a good clock: Clock_Realtime

Clock Realtime would not be a good clock as it measures real 
(wall-clock) time. This won't give a proper understanding of
user space time.

Good clock: Clock_Process_CPUtime_ID
This clock measures the CPU time on all threads in the process.
This will give an accurate measurement on how long the process
spent computing different things. 

8}
[trenduchintala@linuxlab003 test_programs]$ ./getres 1
resolution for realtime clock :          0.000000001

resolution for coarse realtime clock:          0.001000000

The resolution for my coarse realtime clock was far larger than the resolution for
the normal realtime clock. This means that the realtime clock is way more precise than
the coarse realtime clock.

9} Clock Monotic represents an absolute time elapsed based on a starting time in the past. It 
does not incorporate system reboots. The difference between CLOCK_MONOTONIC and CLOCK_MONOTNIC_COARSE
is that the COARSE option updates only once per tick. This creates a lack of precision which
means that the timing of the COARSE clock will not be as accurate as the normal MONOTNOIC clock. 
However, it is a faster clock because the time is only checked at the end of the tick. Therefore,
if a function is getting the time frequently and fine-grained precision isn't as important
it makes sense to use the COARSE clock. 

10} The time it took to run get_time(REALTIMECLOCK, ...) was .000000318 seconds. I
was able to obtain this by getting the REALTIME CLOCK value at the start. Then, I ran a 
get_time(CLOCK) dummy function. And at the end, I captured the clock time again and
compared the two times. 


11} 
[trenduchintala@linuxlab004 test_programs]$ ./timed_parallel_dense_mm 100 100
Generating matrices...
Multiplying matrices...
Multiplication done!
Average Time for Parallel Process: 6071917
Minimum Time: 10000
Maximum Time: 11568770

I think a common case running time would be somewhere in between 200,000 to 300,000 nanoseconds.
I think it would be lower than what is shown above because we are running multiplication
in parallel on 100x100 matrices. In most cases, I believe the dimensions should be lower
in which case, I would err on the lowerbound of the timing we have recieved here. However,
I think the lowest bound would be 10,000. Therefore, the timing woud be about 20x that in 
most cases.

12}

[27073.359668] ktime module initialized
[27087.702794] ktime  module is being unloaded
[27087.702815] Number of seconds: 1  and Number of Nanoseconds: 1458067196

I used the ktime_get_real() function because I wanted to see based on 
clock time how long it was between initialization and unloading. I
was curious to see how it would be in terms of nanoseconds. Also among
the options given, it seemed the most intutitive as get_raw is not 
really used in the kernel. 


----------------------------getres.c----------------------------------------------
#include <time.h>
#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <stdint.h>
#include <stdbool.h>



int main(int argc, char *argv[]){
    bool showRes = argc > 1;
    struct timespec ts;
    struct timespec ts2;

    if(clock_getres(CLOCK_REALTIME, &ts) == -1){
        printf("Error getting realtime clock");
        exit(0);
    }

    if(clock_getres(CLOCK_REALTIME_COARSE, &ts2) == -1){
        printf("Error getting coarse realtime clock");
        exit(0);
    }

    if(showRes){
        printf("resolution for realtime clock : %10jd.%09ld\n",
                (intmax_t) ts.tv_sec, ts.tv_nsec/1000000);
        printf("\n");
        printf("resolution for coarse realtime clock: %10jd.%09ld\n",
                (intmax_t) ts2.tv_sec, ts2.tv_nsec/1000000);
    }
}
                                                                                                                    
                                                                                                                 1,1           All
                                                                                                                 
  ---------------------------getdelay.c------------------------------------------
  
#include <time.h>
#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <stdint.h>
#include <stdbool.h>

#define BILLION 1E9

int main(int argc, char *argv[]){
    bool showRes = argc > 1;
    struct timespec tstart;
    struct timespec tend;
    struct timespec dummyts;

    clock_gettime(CLOCK_REALTIME, &tstart);
    clock_gettime(CLOCK_REALTIME, &dummyts);
    clock_gettime(CLOCK_REALTIME, &tend);

    //double tottime = (tend.tv_sec - tstart.tv_sec) + 
    //    + (tend.tv_nsec - tstart.tv_nsec) / BILLION;

    printf( "%10jd.%09ld\n", tstart.tv_sec, tstart.tv_nsec/1000000 );
    printf( "%10jd.%09ld\n", tend.tv_sec, tend.tv_nsec/1000000 );

    long diff = tend.tv_nsec - tstart.tv_nsec;

    printf( "Total Difference: %09ld\n", diff);
}
                                                                                                                             

------------------------------timed_parallel_dence_mm.c------------------------------------
/******************************************************************************
* 
* dense_mm.c
* 
* This program implements a dense matrix multiply and can be used as a
* hypothetical workload. 
*
* Usage: This program takes a single input describing the size of the matrices
*        to multiply. For an input of size N, it computes A*B = C where each
*        of A, B, and C are matrices of size N*N. Matrices A and B are filled
*        with random values. 
*
* Written Sept 6, 2015 by David Ferry
******************************************************************************/

#include <stdio.h>  //For printf()
#include <stdlib.h> //For exit() and atoi()
#include <assert.h> //For assert()
#include <time.h>
#include <stdint.h>
#include <unistd.h>

const int num_expected_args = 2;
const unsigned sqrt_of_UINT32_MAX = 65536;

// The following line can be used to verify that the parallel computation
// gives identical results to the serial computation. If the verficiation is
// successful then the program executes normally. If the verification fails
// the program will terminate with an assertion error.
//#define VERIFY_PARALLEL

int main( int argc, char* argv[] ){

    unsigned index, row, col; //loop indicies
    unsigned matrix_size, squared_size;
    double *A, *B, *C;
    #ifdef VERIFY_PARALLEL
    double *D;
    #endif
    struct timespec tstart;
    struct timespec tend;
    long ntimes;

    if( argc <  num_expected_args || argc > num_expected_args + 1){
        printf("Usage: ./dense_mm <size of matrices>\n");
        exit(-1);
    }

    if( argc == 3){
        ntimes = atoi(argv[2]);
    }
    else{
        ntimes = 1;
    }
    matrix_size = atoi(argv[1]);

    if( matrix_size > sqrt_of_UINT32_MAX ){
        printf("ERROR: Matrix size must be between zero and 65536!\n");
        exit(-1);
    }

    squared_size = matrix_size * matrix_size;

    printf("Generating matrices...\n");

    A = (double*) malloc( sizeof(double) * squared_size );
    B = (double*) malloc( sizeof(double) * squared_size );
    C = (double*) malloc( sizeof(double) * squared_size );
    #ifdef VERIFY_PARALLEL
    D = (double*) malloc( sizeof(double) * squared_size );
    #endif

    for( index = 0; index < squared_size; index++ ){
        A[index] = (double) rand();
        B[index] = (double) rand();
        C[index] = 0.0;
        #ifdef VERIFY_PARALLEL
        D[index] = 0.0;
        #endif
    }

    printf("Multiplying matrices...\n");
    int curr;
    long maxtime = 0;
    long mintime = 10000;
    long tottime = 0;
    for(curr = 0; curr < ntimes; curr++){
        clock_gettime(CLOCK_MONOTONIC_RAW, &tstart);
        #pragma omp parallel for private(col, row, index)
        for( col = 0; col < matrix_size; col++ ){
            for( row = 0; row < matrix_size; row++ ){
                for( index = 0; index < matrix_size; index++){
                    C[row*matrix_size + col] += A[row*matrix_size + index] * B[index*matrix_size + col];
                }
            }
    }

    for( index = 0; index < squared_size; index++ )
        assert( C[index] == D[index] );
    #endif //ifdef VERIFY_PARALLEL

    printf("Multiplication done!\n");
    //printf("Time Parallel Process Started: %03ld\n", (intmax_t) 
    //    tstart.tv_nsec);
    //printf("Time Parallel Process Ended: %03ld\n", 
    //    tend.tv_nsec);
    printf("Average Time for Parallel Process: %03ld\n", (intmax_t)
            tottime/ntimes);
    printf("Minimum Time: %03ld\n", (intmax_t) mintime);
    printf("Maximum Time: %03ld\n", (intmax_t) maxtime);

    return 0;
}

----------------------------ktime_module.c--------------------------------------------------
/*ktime_module.c - a simple template for a loadable kernal module in 
  Linux,
  based on the hello world kernel module example on pages 338-339 of Robert
  Love's "Linux Kernel Development, Third Edition."
*/

#include <linux/init.h>
#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/timekeeping.h>

ktime_t init_time;
ktime_t exit_time;
ktime_t diff;
    /* init function - logs that initialization happened, returns success */
    static int
    simple_init(void)
{
        printk(KERN_ALERT "ktime module initialized\n");
        init_time = ktime_get_real();
            return 0;
}

/* exit function - logs that the module is being removed */
static void
simple_exit(void)
{
        long ns;
        long sec;
        printk(KERN_ALERT "ktime  module is being unloaded\n");
        exit_time = ktime_get_real();
        diff = ktime_sub(exit_time, init_time);
        ns = ktime_to_ns(diff);
        sec = (ns/1000000000);
        printk("Number of seconds: %ld  and Number of Nanoseconds: %ld\n",
                sec , ns);
}

module_init(simple_init);
module_exit(simple_exit);

MODULE_LICENSE ("GPL");
MODULE_AUTHOR ("LKD Chapter 17");
MODULE_DESCRIPTION ("Simple CSE 422 Module Template");
~                                                                                                                                                 




